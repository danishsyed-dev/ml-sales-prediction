{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9874100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "if project_root not in sys.path: sys.path.insert(0, project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5ad46f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import src.data_handling as data_handling\n",
    "\n",
    "# paths\n",
    "PRODUCTION_MODEL_FOLDER_PATH = 'models/production'\n",
    "DFN_FILE_PATH = os.path.join(PRODUCTION_MODEL_FOLDER_PATH, 'dfn_best.pth')\n",
    "GBM_FILE_PATH =  os.path.join(PRODUCTION_MODEL_FOLDER_PATH, 'gbm_best.pth')\n",
    "EN_FILE_PATH = os.path.join(PRODUCTION_MODEL_FOLDER_PATH, 'en_best.pth')\n",
    "\n",
    "PREPROCESSOR_PATH = 'preprocessors/column_transformer.pkl'\n",
    "\n",
    "file_name = 'online_retail.csv'\n",
    "file_path = os.path.join(project_root, 'data', 'raw', file_name)\n",
    "df = pd.read_csv(file_path)\n",
    "df = data_handling.scripts.sanitize_column_names(df=df)\n",
    "df = data_handling.scripts.structure_missing_values(df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c8bb180",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_sales_items = df[df['quantity'] < 0]\n",
    "print(negative_sales_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b8f9761",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df['invoiceno'] == 'C536379'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "961d7192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# irregular stockcodes\n",
    "short_stockcodes = df[df['stockcode'].str.len() < 5]['stockcode'].unique()\n",
    "print(short_stockcodes)\n",
    "\n",
    "# D = Discount\n",
    "# M = Manual (sales)\n",
    "# m = M (typo)\n",
    "# S = Samples\n",
    "# B = Bad debt\n",
    "# C2 = Cariage (transport)\n",
    "# DOT = Dotcom postage\n",
    "# POST = Postage\n",
    "# PADS = PADS TO MATCH ALL CUSHIONS\n",
    "# CRUK = CRUK Commission (commission fee paid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bc7f708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check what s inside\n",
    "# print(df[df['stockcode'] == 'S'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72338925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace typo m to M\n",
    "df['stockcode'] = df['stockcode'].replace('m', 'M')\n",
    "\n",
    "short_stockcodes = df[df['stockcode'].str.len() < 5]['stockcode'].unique()\n",
    "print(short_stockcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ceaf341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop irrelevant stockcodes to sales (B, CRUK, C2)\n",
    "stockcodes_to_drop = ['B', 'CRUK', 'C2']\n",
    "df = df[~df['stockcode'].isin(stockcodes_to_drop)]\n",
    "\n",
    "short_stockcodes = df[df['stockcode'].str.len() < 5]['stockcode'].unique()\n",
    "print(short_stockcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bb8fdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0efbc2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary features\n",
    "if 'description' in df.columns.tolist(): df = df.drop(columns='description')\n",
    "\n",
    "# adds quantity momentum features\n",
    "df['invoicedate'] = pd.to_datetime(df['invoicedate'], errors='coerce')\n",
    "df['year'] = df['invoicedate'].dt.year\n",
    "df['year_month'] = df['invoicedate'].dt.to_period('M')\n",
    "df['month_name'] = df['invoicedate'].dt.strftime('%b')\n",
    "df['day_of_week'] = df['invoicedate'].dt.strftime('%a')\n",
    "df['sales'] = df['quantity'] * df['unitprice']\n",
    "\n",
    "_df_prod_month_agg = df.copy().groupby(['stockcode', 'year_month']).agg(\n",
    "    prod_total_monthly_sales=('sales', 'sum'),\n",
    "    prod_ave_monthly_price=('unitprice', 'mean')\n",
    ").reset_index().sort_values(by=['stockcode', 'year_month'])\n",
    "_df_prod_month_agg['product_avg_sales_last_month'] = _df_prod_month_agg.groupby('stockcode')['prod_total_monthly_sales'].shift(1)\n",
    "_df_prod_last_month_agg = _df_prod_month_agg.groupby('stockcode')['product_avg_sales_last_month'].mean().reset_index()\n",
    "_df_prod_last_month_agg_renamed = _df_prod_last_month_agg.rename(\n",
    "    columns={'product_avg_sales_last_month': 'new_product_avg_sales_last_month'}\n",
    ")\n",
    "\n",
    "df_fin = pd.merge(\n",
    "    df,\n",
    "    _df_prod_last_month_agg_renamed[['stockcode', 'new_product_avg_sales_last_month']],\n",
    "    on='stockcode',\n",
    "    how='left'\n",
    ")\n",
    "df_fin['product_avg_sales_last_month'] = df_fin['new_product_avg_sales_last_month']\n",
    "df_fin = df_fin.drop(columns='new_product_avg_sales_last_month', axis=1)\n",
    "df_fin['product_avg_sales_last_month'] = df_fin['product_avg_sales_last_month'].fillna(value=0)\n",
    "\n",
    "\n",
    "# add customer related features\n",
    "# handle customer registration\n",
    "df_fin['is_registered'] = np.where(df_fin['customerid'].isna(), 0, 1)\n",
    "df_fin['customerid'] = df_fin['customerid'].fillna('unknown').astype('str')\n",
    "\n",
    "## 1. customer_recency_days\n",
    "_df_all_customers_year_month = pd.MultiIndex.from_product(\n",
    "    [df_fin['customerid'].unique(), df_fin['year_month'].unique()], # type: ignore\n",
    "    names=['customerid', 'year_month']\n",
    ").to_frame(index=False).sort_values(by=['customerid', 'year_month']).reset_index(drop=True)\n",
    "_df_customer_monthly_agg = df_fin.copy().groupby(['customerid', 'year_month']).agg(\n",
    "    monthly_sales=('sales', 'sum'),\n",
    "    monthly_unique_invoices=('invoiceno', 'nunique'),\n",
    "    monthly_last_purchase_date=('invoicedate', 'max')\n",
    ").reset_index()\n",
    "_df_cus = _df_all_customers_year_month.merge(\n",
    "    _df_customer_monthly_agg,\n",
    "    on=['customerid', 'year_month'],\n",
    "    how='left'\n",
    ").sort_values(by=['customerid', 'year_month'])\n",
    "\n",
    "_df_cus['pfin_last_purchase_date'] = _df_cus.groupby('customerid')['monthly_last_purchase_date'].shift(1)\n",
    "_df_cus['invoice_timestamp_end'] = _df_cus['year_month'].dt.end_time\n",
    "_df_cus['customer_recency_days'] = (_df_cus['invoice_timestamp_end'] - _df_cus['pfin_last_purchase_date']).dt.days\n",
    "df_fin['customer_recency_days'] = _df_cus['customer_recency_days']\n",
    "max_recency = _df_cus['customer_recency_days'].max()\n",
    "df_fin['customer_recency_days'] = df_fin['customer_recency_days'].fillna(value=max_recency + 30)\n",
    "df_fin['customer_recency_days'] = df_fin['customer_recency_days'].fillna(365)\n",
    "\n",
    "## 2. customer_total_spend_ltm\n",
    "if not _df_cus['customerid'].isna().all():\n",
    "    _df_cus['customer_total_spend_ltm'] = _df_cus.groupby('customerid')['monthly_sales'].rolling(window=3, closed='left').sum().reset_index(level=0, drop=True)\n",
    "    df_fin['customer_total_spend_ltm'] = _df_cus['customer_total_spend_ltm']\n",
    "    df_fin['customer_total_spend_ltm'] = df_fin['customer_total_spend_ltm'].fillna(value=0)\n",
    "\n",
    "    ## 3. customer_freq_ltm\n",
    "    _df_cus['customer_freq_ltm'] = _df_cus.groupby('customerid')['monthly_unique_invoices'].rolling(window=3, closed='left').sum().reset_index(level=0, drop=True)\n",
    "    df_fin['customer_freq_ltm'] = _df_cus['customer_freq_ltm']\n",
    "    df_fin['customer_freq_ltm'] = df_fin['customer_freq_ltm'].fillna(value=0)\n",
    "else:\n",
    "    df_fin['customer_freq_ltm'] = 0\n",
    "    df_fin['customer_total_spend_ltm'] = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# after computing customer sales features, drop unnecessary data\n",
    "stockcodes_to_drop = ['D', 'S']\n",
    "df_fin = df_fin[~df_fin['stockcode'].isin(stockcodes_to_drop)]\n",
    "df_fin = df_fin.drop(columns=['month_name', 'quantity'], axis='columns')\n",
    "\n",
    "# sales (drop negative vals)\n",
    "df_fin['sales'] = pd.to_numeric(df_fin['sales'], errors='coerce')\n",
    "df_fin['sales'] = df_fin['sales'].fillna(0)\n",
    "df_fin = df_fin[df_fin['sales'] > 0]\n",
    "\n",
    "\n",
    "# dtype transformation\n",
    "df_fin['year_month'] = df_fin['year_month'].dt.month\n",
    "df_fin['invoicedate'] = df_fin['invoicedate'].astype(int) / 10 ** 9\n",
    "\n",
    "\n",
    "# imputation\n",
    "df_fin['customerid'] = df_fin['customerid'].fillna(value='unknown')\n",
    "df_fin['stockcode'] = df_fin['stockcode'].fillna(value='unknown')\n",
    "df_fin['invoiceno'] = df_fin['invoiceno'].fillna(value='unknown')\n",
    "# df_fin['quantity'] = df_fin['quantity'].fillna(value=0)\n",
    "\n",
    "# imputation (values referred to stockcode)\n",
    "df_imputed = df_fin.copy().sort_values(by='stockcode').reset_index(drop=True)\n",
    "df_stockcode = df_imputed.groupby('stockcode', as_index=False).agg(\n",
    "    imputed_country=('country', lambda x: x.mode().iloc[0] if not x.mode().empty else 'unknown'),\n",
    "    imputed_unitprice=('unitprice', 'median')\n",
    ")\n",
    "df_fin = pd.merge(df_fin, df_stockcode, on='stockcode', how='left')\n",
    "df_fin['country'] = df_fin['country'].fillna(df_fin['imputed_country'])\n",
    "\n",
    "global_median = df_fin['unitprice'].median()\n",
    "df_fin['unitprice'] = df_fin['unitprice'].fillna(df_fin['imputed_unitprice'])\n",
    "df_fin['unitprice'] = df_fin['unitprice'].fillna(global_median)\n",
    "df_fin = df_fin.drop(columns=['imputed_country', 'imputed_unitprice'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df_fin['is_return'] = (df_fin['sales'] < 0).astype(int)\n",
    "\n",
    "# drop negative sales (return etc)\n",
    "# df_fin_log = df_fin.copy()\n",
    "# df_fin_log = df_fin_log[df_fin_log['sales'] > 0]\n",
    "# df_fin_log['sales'] = np.where(df_fin_log['is_return'] == 1, 0, df_fin_log['sales'])\n",
    "\n",
    "# transform sales to logged values\n",
    "alpha = 1e-3\n",
    "df_fin['sales'] = np.log(df_fin['sales'] + alpha)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea67ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_fin.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2732ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# classify num and cat columns\n",
    "target_col = 'sales'\n",
    "\n",
    "num_cols, cat_cols = data_handling.scripts.categorize_num_cat_cols(df=df, target_col=target_col)\n",
    "if cat_cols: \n",
    "    for col in cat_cols: df[col] = df[col].astype('string')\n",
    "\n",
    "\n",
    "# creates train, val, test datasets\n",
    "y = df[target_col]\n",
    "X = df.copy().drop(target_col, axis='columns')\n",
    "\n",
    "test_size, random_state = 50000, 42\n",
    "X_tv, X_test, y_tv, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tv, y_tv, test_size=test_size, random_state=random_state, shuffle=True)\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35547264",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, preprocessor = data_handling.scripts.transform_input(X_train, X_val, X_test, num_cols=num_cols, cat_cols=cat_cols)\n",
    "\n",
    "import src.model.torch_model as t\n",
    "\n",
    "file_path = os.path.join(project_root, 'models', 'production', 'dfn_best.pth')\n",
    "model = t.scripts.load_model(input_dim=X_train.shape[1], file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0148e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "stockcode = '85123A'\n",
    "\n",
    "df = df_fin.copy()\n",
    "df_stockcode = df[df['stockcode'] == stockcode]\n",
    "# print(df_stockcode['quantity'].unique())\n",
    "\n",
    "# df_stockcode = data_handling.scripts.structure_missing_values(df=df_stockcode)\n",
    "# df_stockcode = data_handling.scripts.handle_feature_engineering(df=df_stockcode)\n",
    "\n",
    "# print(df_stockcode['quantity'].unique())\n",
    "\n",
    "print(df_stockcode.head().transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7e5f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "X = df_stockcode.copy().drop(columns=target_col)\n",
    "y = df_stockcode.copy()[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1000, random_state=random_state, shuffle=True)\n",
    "\n",
    "X_train = preprocessor.transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "batch_size = 32\n",
    "train_data_loader = t.scripts.create_torch_data_loader(X=X_train, y=y_train, batch_size=batch_size)\n",
    "val_data_loader = t.scripts.create_torch_data_loader(X=X_val, y=y_val, batch_size=batch_size)\n",
    "# retrain the best model\n",
    "model, _ = t.scripts.train_model(\n",
    "    model=model,\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=0.001),\n",
    "    criterion=torch.nn.MSELoss(),\n",
    "    num_epochs=50,\n",
    "    min_delta=0.00001,\n",
    "    patience=10,\n",
    "    train_data_loader=train_data_loader,\n",
    "    val_data_loader=val_data_loader,\n",
    "    device_type='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0b8d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src._utils import main_logger\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import src.model.torch_model as t\n",
    "\n",
    "file_path = os.path.join(project_root, 'models', 'production', 'dfn_best.pth')\n",
    "model = t.scripts.load_model(input_dim=X_train.shape[1], file_path=file_path)\n",
    "\n",
    "min_price = 2\n",
    "max_price = 100\n",
    "NUM_PRICE_BINS = 1000\n",
    "price_range = np.linspace(min_price, max_price, num=NUM_PRICE_BINS)\n",
    "\n",
    "data = {}\n",
    "\n",
    "customerid = data.get('customerid', 'unknown') if data else 'unknown'\n",
    "try: customer_recency_days = df_stockcode.loc[df_stockcode['customerid'] == customerid, 'customer_recency_days_latest'].iloc[0] # type:ignore\n",
    "except: customer_recency_days = 365\n",
    "try: customer_total_spend_ltm = df_stockcode.loc[df_stockcode['customerid'] == customerid, 'customer_total_spend_ltm_latest'].iloc[0] # type:ignore\n",
    "except: customer_total_spend_ltm = 0\n",
    "try: customer_freq_ltm =  df_stockcode.loc[df_stockcode['customerid'] == customerid, 'customer_freq_ltm_latest'].iloc[0] # type:ignore\n",
    "except: customer_freq_ltm = 0\n",
    "\n",
    "new_data = {\n",
    "    'invoicedate': [np.datetime64(datetime.datetime.now())] * NUM_PRICE_BINS,\n",
    "    'invoiceno': [data.get('invoiceno', np.nan)] * NUM_PRICE_BINS,\n",
    "    'stockcode': [stockcode] * NUM_PRICE_BINS,\n",
    "    'sales': [np.nan] * NUM_PRICE_BINS,\n",
    "    'customerid': [customerid] * NUM_PRICE_BINS,\n",
    "    'country': [data.get('country', df_stockcode.loc[0, 'country']) if df_stockcode is not None else np.nan] * NUM_PRICE_BINS,\n",
    "    'unitprice': price_range,\n",
    "    'product_avg_sales_last_month': [df_stockcode.loc[0, 'product_avg_sales_last_month'] if df_stockcode is not None else 0] * NUM_PRICE_BINS,\n",
    "    'is_registered': [True if customerid else False] * NUM_PRICE_BINS,\n",
    "    'customer_recency_days': [customer_recency_days] * NUM_PRICE_BINS,\n",
    "    'customer_total_spend_ltm': [customer_total_spend_ltm] * NUM_PRICE_BINS,\n",
    "    'customer_freq_ltm': [customer_freq_ltm] * NUM_PRICE_BINS,\n",
    "    'is_return': [False] * NUM_PRICE_BINS,\n",
    "}\n",
    "new_df = pd.DataFrame(new_data)\n",
    "\n",
    "# add dt related features\n",
    "new_df['year'] = new_df['invoicedate'].dt.year\n",
    "new_df['year_month'] = new_df['invoicedate'].dt.to_period('M')\n",
    "new_df['day_of_week'] = new_df['invoicedate'].dt.strftime('%a')\n",
    "new_df['invoicedate'] = new_df['invoicedate'].astype(int) / 10 ** 9\n",
    "\n",
    "\n",
    "# transform input data\n",
    "target_col = 'sales'\n",
    "X = new_df.copy().drop(target_col, axis=1)\n",
    "X = X.sample(frac=1).reset_index(drop=True)\n",
    "if preprocessor: X = preprocessor.transform(X)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "input_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "epsilon = 1e-10\n",
    "with torch.inference_mode():\n",
    "    y_pred = model(input_tensor)\n",
    "    y_pred = y_pred.cpu().numpy().flatten()\n",
    "    y_pred_actual = np.exp(y_pred + epsilon)\n",
    "    main_logger.info(f\"primary model's prediction for stockcode {stockcode} - actual sales ${y_pred_actual}\")\n",
    "\n",
    "\n",
    "df_ = new_df.copy()\n",
    "df_['sales'] = y_pred_actual\n",
    "df_ = df_.sort_values(by='unitprice')\n",
    "\n",
    "optimal_row = df_.loc[df_['sales'].idxmax()]\n",
    "optimal_price = optimal_row['unitprice']\n",
    "best_sales = optimal_row['sales']\n",
    "\n",
    "all_outputs = []\n",
    "for _, row in df_.iterrows():\n",
    "    current_output = {\n",
    "        \"stockcode\": stockcode,\n",
    "        \"unit_price\": float(row['unitprice']),\n",
    "        \"predicted_sales\": float(row['sales']),\n",
    "        \"optimal_unit_price\": float(optimal_price), # type: ignore\n",
    "        \"max_predicted_sales\": float(best_sales) * 30, # type: ignore\n",
    "    }\n",
    "    all_outputs.append(current_output)\n",
    "\n",
    "    # print(float(row['quantity'] * row['unitprice']))\n",
    "\n",
    "print(optimal_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f578304",
   "metadata": {},
   "outputs": [],
   "source": [
    "## comment out \n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(10, 6)) \n",
    "# plt.scatter(df_['unitprice'], df_['sales'], color='blue', label='Predicted Sales')\n",
    "\n",
    "# # Highlight the optimal price point on the graph\n",
    "# plt.scatter(optimal_price, best_sales, color='red', s=100, zorder=5, label='Optimal Price Point')\n",
    "\n",
    "# # Add labels and a title for clarity\n",
    "# plt.xlabel('Unit Price', fontsize=12)\n",
    "# plt.ylabel('Predicted Sales', fontsize=12)\n",
    "# plt.title('Predicted Sales vs. Unit Price', fontsize=14)\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.xticks(df_['unitprice']) # Ensure all price points are shown on the x-axis\n",
    "\n",
    "# # Annotate the optimal point with its values\n",
    "# plt.annotate(\n",
    "#     f'Optimal Price: ${optimal_price}\\nMax Sales: {best_sales}',\n",
    "#     xy=(optimal_price, best_sales),\n",
    "#     xytext=(optimal_price + 2, best_sales + 100),\n",
    "#     arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "#     fontsize=10\n",
    "# )\n",
    "# plt.savefig('my_plot.png')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}